{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "# 数据下载和标准化\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=0)\n",
    " \n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    " \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "class CNNNet_1(nn.Module):\n",
    "    \"\"\"\n",
    "    构建卷积神经网络\n",
    "    搭建 两个conv1 conv2 层 两个pool 层 两个全连接层\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNNet_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=36, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1296, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 36 * 6 * 6)\n",
    "        x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x\n",
    " \n",
    "class CNNNet_2(nn.Module):\n",
    "    #增加卷积层和池化层，加深网络结构\n",
    "    def __init__(self):\n",
    "        super(CNNNet_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNNNet_3(nn.Module):\n",
    "    #增加卷积核大小和步长，减小卷积层个数，增加全连接层个数\n",
    "    def __init__(self):\n",
    "        super(CNNNet_3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7, stride=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(2304, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 2304)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们知道，学习率是神经⽹络训练中⼀个⽐较重要的超参数，学习率的好坏，在⼀定程度上能\n",
    "对神经⽹络最终的学习效果造成影响。我们希望你设计实验探究不同学习率（1e-6~1e-1，⼗倍\n",
    "率变化）对最终结果的影响，如何理解它对模型训练造成的影响？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.303\n",
      "[1, 4000] loss: 2.303\n",
      "[1, 6000] loss: 2.303\n",
      "[1, 8000] loss: 2.303\n",
      "[1,10000] loss: 2.303\n",
      "[1,12000] loss: 2.303\n",
      "[2, 2000] loss: 2.303\n",
      "[2, 4000] loss: 2.303\n",
      "[2, 6000] loss: 2.303\n",
      "[2, 8000] loss: 2.303\n",
      "[2,10000] loss: 2.303\n",
      "[2,12000] loss: 2.303\n",
      "[3, 2000] loss: 2.303\n",
      "[3, 4000] loss: 2.303\n",
      "[3, 6000] loss: 2.303\n",
      "[3, 8000] loss: 2.303\n",
      "[3,10000] loss: 2.303\n",
      "[3,12000] loss: 2.303\n",
      "[4, 2000] loss: 2.303\n",
      "[4, 4000] loss: 2.303\n",
      "[4, 6000] loss: 2.303\n",
      "[4, 8000] loss: 2.303\n",
      "[4,10000] loss: 2.303\n",
      "[4,12000] loss: 2.303\n",
      "[5, 2000] loss: 2.303\n",
      "[5, 4000] loss: 2.303\n",
      "[5, 6000] loss: 2.303\n",
      "[5, 8000] loss: 2.303\n",
      "[5,10000] loss: 2.303\n",
      "[5,12000] loss: 2.303\n",
      "[6, 2000] loss: 2.303\n",
      "[6, 4000] loss: 2.303\n",
      "[6, 6000] loss: 2.303\n",
      "[6, 8000] loss: 2.303\n",
      "[6,10000] loss: 2.303\n",
      "[6,12000] loss: 2.303\n",
      "[7, 2000] loss: 2.303\n",
      "[7, 4000] loss: 2.303\n",
      "[7, 6000] loss: 2.303\n",
      "[7, 8000] loss: 2.303\n",
      "[7,10000] loss: 2.303\n",
      "[7,12000] loss: 2.303\n",
      "[8, 2000] loss: 2.303\n",
      "[8, 4000] loss: 2.303\n",
      "[8, 6000] loss: 2.303\n",
      "[8, 8000] loss: 2.303\n",
      "[8,10000] loss: 2.303\n",
      "[8,12000] loss: 2.303\n",
      "[9, 2000] loss: 2.303\n",
      "[9, 4000] loss: 2.303\n",
      "[9, 6000] loss: 2.303\n",
      "[9, 8000] loss: 2.303\n",
      "[9,10000] loss: 2.303\n",
      "[9,12000] loss: 2.303\n",
      "[10, 2000] loss: 2.303\n",
      "[10, 4000] loss: 2.303\n",
      "[10, 6000] loss: 2.303\n",
      "[10, 8000] loss: 2.303\n",
      "[10,10000] loss: 2.303\n",
      "[10,12000] loss: 2.303\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 10 %\n",
      "Accuracy of plane: 100 %\n",
      "Accuracy of   car:  0 %\n",
      "Accuracy of  bird:  0 %\n",
      "Accuracy of   cat:  0 %\n",
      "Accuracy of  deer:  0 %\n",
      "Accuracy of   dog:  0 %\n",
      "Accuracy of  frog:  0 %\n",
      "Accuracy of horse:  0 %\n",
      "Accuracy of  ship:  0 %\n",
      "Accuracy of truck:  0 %\n"
     ]
    }
   ],
   "source": [
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    " \n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "#各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.088\n",
      "[1, 4000] loss: 1.872\n",
      "[1, 6000] loss: 1.831\n",
      "[1, 8000] loss: 1.836\n",
      "[1,10000] loss: 1.826\n",
      "[1,12000] loss: 1.788\n",
      "[2, 2000] loss: 1.796\n",
      "[2, 4000] loss: 1.795\n",
      "[2, 6000] loss: 1.772\n",
      "[2, 8000] loss: 1.791\n",
      "[2,10000] loss: 1.800\n",
      "[2,12000] loss: 1.795\n",
      "[3, 2000] loss: 1.799\n",
      "[3, 4000] loss: 1.769\n",
      "[3, 6000] loss: 1.769\n",
      "[3, 8000] loss: 1.786\n",
      "[3,10000] loss: 1.801\n",
      "[3,12000] loss: 1.806\n",
      "[4, 2000] loss: 1.780\n",
      "[4, 4000] loss: 1.827\n",
      "[4, 6000] loss: 1.812\n",
      "[4, 8000] loss: 1.780\n",
      "[4,10000] loss: 1.819\n",
      "[4,12000] loss: 1.812\n",
      "[5, 2000] loss: 1.793\n",
      "[5, 4000] loss: 1.791\n",
      "[5, 6000] loss: 1.833\n",
      "[5, 8000] loss: 1.807\n",
      "[5,10000] loss: 1.803\n",
      "[5,12000] loss: 1.884\n",
      "[6, 2000] loss: 1.873\n",
      "[6, 4000] loss: 1.816\n",
      "[6, 6000] loss: 1.831\n",
      "[6, 8000] loss: 1.865\n",
      "[6,10000] loss: 1.844\n",
      "[6,12000] loss: 1.851\n",
      "[7, 2000] loss: 1.804\n",
      "[7, 4000] loss: 1.803\n",
      "[7, 6000] loss: 1.801\n",
      "[7, 8000] loss: 1.800\n",
      "[7,10000] loss: 1.808\n",
      "[7,12000] loss: 1.845\n",
      "[8, 2000] loss: 1.797\n",
      "[8, 4000] loss: 1.793\n",
      "[8, 6000] loss: 1.934\n",
      "[8, 8000] loss: 1.816\n",
      "[8,10000] loss: 1.806\n",
      "[8,12000] loss: 1.804\n",
      "[9, 2000] loss: 1.822\n",
      "[9, 4000] loss: 1.826\n",
      "[9, 6000] loss: 1.874\n",
      "[9, 8000] loss: 1.814\n",
      "[9,10000] loss: 1.841\n",
      "[9,12000] loss: 1.819\n",
      "[10, 2000] loss: 1.844\n",
      "[10, 4000] loss: 1.840\n",
      "[10, 6000] loss: 1.881\n",
      "[10, 8000] loss: 1.846\n",
      "[10,10000] loss: 1.851\n",
      "[10,12000] loss: 1.811\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 35 %\n",
      "Accuracy of plane: 59 %\n",
      "Accuracy of   car: 46 %\n",
      "Accuracy of  bird: 17 %\n",
      "Accuracy of   cat: 50 %\n",
      "Accuracy of  deer:  9 %\n",
      "Accuracy of   dog: 10 %\n",
      "Accuracy of  frog: 64 %\n",
      "Accuracy of horse: 38 %\n",
      "Accuracy of  ship: 22 %\n",
      "Accuracy of truck: 37 %\n"
     ]
    }
   ],
   "source": [
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)  \n",
    " \n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "#各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.006\n",
      "[1, 4000] loss: 1.629\n",
      "[1, 6000] loss: 1.503\n",
      "[1, 8000] loss: 1.446\n",
      "[1,10000] loss: 1.349\n",
      "[1,12000] loss: 1.272\n",
      "[2, 2000] loss: 1.176\n",
      "[2, 4000] loss: 1.155\n",
      "[2, 6000] loss: 1.139\n",
      "[2, 8000] loss: 1.102\n",
      "[2,10000] loss: 1.077\n",
      "[2,12000] loss: 1.061\n",
      "[3, 2000] loss: 0.945\n",
      "[3, 4000] loss: 0.948\n",
      "[3, 6000] loss: 0.944\n",
      "[3, 8000] loss: 0.938\n",
      "[3,10000] loss: 0.943\n",
      "[3,12000] loss: 0.931\n",
      "[4, 2000] loss: 0.798\n",
      "[4, 4000] loss: 0.791\n",
      "[4, 6000] loss: 0.832\n",
      "[4, 8000] loss: 0.829\n",
      "[4,10000] loss: 0.841\n",
      "[4,12000] loss: 0.837\n",
      "[5, 2000] loss: 0.701\n",
      "[5, 4000] loss: 0.712\n",
      "[5, 6000] loss: 0.723\n",
      "[5, 8000] loss: 0.750\n",
      "[5,10000] loss: 0.749\n",
      "[5,12000] loss: 0.752\n",
      "[6, 2000] loss: 0.596\n",
      "[6, 4000] loss: 0.588\n",
      "[6, 6000] loss: 0.647\n",
      "[6, 8000] loss: 0.674\n",
      "[6,10000] loss: 0.664\n",
      "[6,12000] loss: 0.680\n",
      "[7, 2000] loss: 0.511\n",
      "[7, 4000] loss: 0.556\n",
      "[7, 6000] loss: 0.559\n",
      "[7, 8000] loss: 0.579\n",
      "[7,10000] loss: 0.613\n",
      "[7,12000] loss: 0.616\n",
      "[8, 2000] loss: 0.436\n",
      "[8, 4000] loss: 0.469\n",
      "[8, 6000] loss: 0.500\n",
      "[8, 8000] loss: 0.508\n",
      "[8,10000] loss: 0.544\n",
      "[8,12000] loss: 0.557\n",
      "[9, 2000] loss: 0.367\n",
      "[9, 4000] loss: 0.396\n",
      "[9, 6000] loss: 0.446\n",
      "[9, 8000] loss: 0.457\n",
      "[9,10000] loss: 0.477\n",
      "[9,12000] loss: 0.521\n",
      "[10, 2000] loss: 0.316\n",
      "[10, 4000] loss: 0.367\n",
      "[10, 6000] loss: 0.390\n",
      "[10, 8000] loss: 0.414\n",
      "[10,10000] loss: 0.433\n",
      "[10,12000] loss: 0.461\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 67 %\n",
      "Accuracy of plane: 73 %\n",
      "Accuracy of   car: 80 %\n",
      "Accuracy of  bird: 61 %\n",
      "Accuracy of   cat: 47 %\n",
      "Accuracy of  deer: 62 %\n",
      "Accuracy of   dog: 56 %\n",
      "Accuracy of  frog: 77 %\n",
      "Accuracy of horse: 65 %\n",
      "Accuracy of  ship: 78 %\n",
      "Accuracy of truck: 73 %\n"
     ]
    }
   ],
   "source": [
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  \n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "#各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.302\n",
      "[1, 4000] loss: 2.298\n",
      "[1, 6000] loss: 2.294\n",
      "[1, 8000] loss: 2.285\n",
      "[1,10000] loss: 2.268\n",
      "[1,12000] loss: 2.217\n",
      "[2, 2000] loss: 2.127\n",
      "[2, 4000] loss: 2.063\n",
      "[2, 6000] loss: 2.010\n",
      "[2, 8000] loss: 1.947\n",
      "[2,10000] loss: 1.912\n",
      "[2,12000] loss: 1.877\n",
      "[3, 2000] loss: 1.827\n",
      "[3, 4000] loss: 1.783\n",
      "[3, 6000] loss: 1.775\n",
      "[3, 8000] loss: 1.769\n",
      "[3,10000] loss: 1.755\n",
      "[3,12000] loss: 1.734\n",
      "[4, 2000] loss: 1.660\n",
      "[4, 4000] loss: 1.619\n",
      "[4, 6000] loss: 1.583\n",
      "[4, 8000] loss: 1.577\n",
      "[4,10000] loss: 1.582\n",
      "[4,12000] loss: 1.546\n",
      "[5, 2000] loss: 1.520\n",
      "[5, 4000] loss: 1.461\n",
      "[5, 6000] loss: 1.376\n",
      "[5, 8000] loss: 1.359\n",
      "[5,10000] loss: 1.337\n",
      "[5,12000] loss: 1.323\n",
      "[6, 2000] loss: 1.291\n",
      "[6, 4000] loss: 1.287\n",
      "[6, 6000] loss: 1.278\n",
      "[6, 8000] loss: 1.265\n",
      "[6,10000] loss: 1.272\n",
      "[6,12000] loss: 1.252\n",
      "[7, 2000] loss: 1.208\n",
      "[7, 4000] loss: 1.207\n",
      "[7, 6000] loss: 1.205\n",
      "[7, 8000] loss: 1.194\n",
      "[7,10000] loss: 1.170\n",
      "[7,12000] loss: 1.189\n",
      "[8, 2000] loss: 1.156\n",
      "[8, 4000] loss: 1.117\n",
      "[8, 6000] loss: 1.129\n",
      "[8, 8000] loss: 1.130\n",
      "[8,10000] loss: 1.120\n",
      "[8,12000] loss: 1.106\n",
      "[9, 2000] loss: 1.062\n",
      "[9, 4000] loss: 1.076\n",
      "[9, 6000] loss: 1.064\n",
      "[9, 8000] loss: 1.075\n",
      "[9,10000] loss: 1.057\n",
      "[9,12000] loss: 1.048\n",
      "[10, 2000] loss: 1.002\n",
      "[10, 4000] loss: 0.996\n",
      "[10, 6000] loss: 1.032\n",
      "[10, 8000] loss: 1.001\n",
      "[10,10000] loss: 1.019\n",
      "[10,12000] loss: 1.015\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 62 %\n",
      "Accuracy of plane: 62 %\n",
      "Accuracy of   car: 71 %\n",
      "Accuracy of  bird: 42 %\n",
      "Accuracy of   cat: 37 %\n",
      "Accuracy of  deer: 47 %\n",
      "Accuracy of   dog: 62 %\n",
      "Accuracy of  frog: 73 %\n",
      "Accuracy of horse: 69 %\n",
      "Accuracy of  ship: 82 %\n",
      "Accuracy of truck: 79 %\n"
     ]
    }
   ],
   "source": [
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)  \n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "#各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.300\n",
      "[1, 4000] loss: 2.298\n",
      "[1, 6000] loss: 2.296\n",
      "[1, 8000] loss: 2.292\n",
      "[1,10000] loss: 2.289\n",
      "[1,12000] loss: 2.287\n",
      "[2, 2000] loss: 2.282\n",
      "[2, 4000] loss: 2.279\n",
      "[2, 6000] loss: 2.276\n",
      "[2, 8000] loss: 2.271\n",
      "[2,10000] loss: 2.264\n",
      "[2,12000] loss: 2.257\n",
      "[3, 2000] loss: 2.248\n",
      "[3, 4000] loss: 2.242\n",
      "[3, 6000] loss: 2.231\n",
      "[3, 8000] loss: 2.221\n",
      "[3,10000] loss: 2.214\n",
      "[3,12000] loss: 2.201\n",
      "[4, 2000] loss: 2.191\n",
      "[4, 4000] loss: 2.172\n",
      "[4, 6000] loss: 2.167\n",
      "[4, 8000] loss: 2.148\n",
      "[4,10000] loss: 2.147\n",
      "[4,12000] loss: 2.129\n",
      "[5, 2000] loss: 2.109\n",
      "[5, 4000] loss: 2.096\n",
      "[5, 6000] loss: 2.094\n",
      "[5, 8000] loss: 2.087\n",
      "[5,10000] loss: 2.083\n",
      "[5,12000] loss: 2.066\n",
      "[6, 2000] loss: 2.072\n",
      "[6, 4000] loss: 2.041\n",
      "[6, 6000] loss: 2.046\n",
      "[6, 8000] loss: 2.056\n",
      "[6,10000] loss: 2.038\n",
      "[6,12000] loss: 2.039\n",
      "[7, 2000] loss: 2.036\n",
      "[7, 4000] loss: 2.013\n",
      "[7, 6000] loss: 2.031\n",
      "[7, 8000] loss: 2.008\n",
      "[7,10000] loss: 1.999\n",
      "[7,12000] loss: 1.998\n",
      "[8, 2000] loss: 1.993\n",
      "[8, 4000] loss: 1.989\n",
      "[8, 6000] loss: 1.982\n",
      "[8, 8000] loss: 1.989\n",
      "[8,10000] loss: 1.977\n",
      "[8,12000] loss: 1.954\n",
      "[9, 2000] loss: 1.954\n",
      "[9, 4000] loss: 1.955\n",
      "[9, 6000] loss: 1.954\n",
      "[9, 8000] loss: 1.947\n",
      "[9,10000] loss: 1.936\n",
      "[9,12000] loss: 1.917\n",
      "[10, 2000] loss: 1.930\n",
      "[10, 4000] loss: 1.906\n",
      "[10, 6000] loss: 1.916\n",
      "[10, 8000] loss: 1.907\n",
      "[10,10000] loss: 1.909\n",
      "[10,12000] loss: 1.897\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 35 %\n",
      "Accuracy of plane: 51 %\n",
      "Accuracy of   car: 46 %\n",
      "Accuracy of  bird: 20 %\n",
      "Accuracy of   cat: 30 %\n",
      "Accuracy of  deer: 37 %\n",
      "Accuracy of   dog: 31 %\n",
      "Accuracy of  frog:  0 %\n",
      "Accuracy of horse: 46 %\n",
      "Accuracy of  ship: 46 %\n",
      "Accuracy of truck: 41 %\n"
     ]
    }
   ],
   "source": [
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9) \n",
    " \n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "# 各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.301\n",
      "[1, 4000] loss: 2.302\n",
      "[1, 6000] loss: 2.302\n",
      "[1, 8000] loss: 2.301\n",
      "[1,10000] loss: 2.301\n",
      "[1,12000] loss: 2.302\n",
      "[2, 2000] loss: 2.301\n",
      "[2, 4000] loss: 2.301\n",
      "[2, 6000] loss: 2.301\n",
      "[2, 8000] loss: 2.301\n",
      "[2,10000] loss: 2.301\n",
      "[2,12000] loss: 2.301\n",
      "[3, 2000] loss: 2.300\n",
      "[3, 4000] loss: 2.300\n",
      "[3, 6000] loss: 2.301\n",
      "[3, 8000] loss: 2.301\n",
      "[3,10000] loss: 2.301\n",
      "[3,12000] loss: 2.301\n",
      "[4, 2000] loss: 2.301\n",
      "[4, 4000] loss: 2.301\n",
      "[4, 6000] loss: 2.301\n",
      "[4, 8000] loss: 2.300\n",
      "[4,10000] loss: 2.300\n",
      "[4,12000] loss: 2.300\n",
      "[5, 2000] loss: 2.301\n",
      "[5, 4000] loss: 2.300\n",
      "[5, 6000] loss: 2.301\n",
      "[5, 8000] loss: 2.300\n",
      "[5,10000] loss: 2.299\n",
      "[5,12000] loss: 2.300\n",
      "[6, 2000] loss: 2.300\n",
      "[6, 4000] loss: 2.299\n",
      "[6, 6000] loss: 2.300\n",
      "[6, 8000] loss: 2.299\n",
      "[6,10000] loss: 2.300\n",
      "[6,12000] loss: 2.300\n",
      "[7, 2000] loss: 2.299\n",
      "[7, 4000] loss: 2.299\n",
      "[7, 6000] loss: 2.300\n",
      "[7, 8000] loss: 2.299\n",
      "[7,10000] loss: 2.299\n",
      "[7,12000] loss: 2.299\n",
      "[8, 2000] loss: 2.299\n",
      "[8, 4000] loss: 2.299\n",
      "[8, 6000] loss: 2.299\n",
      "[8, 8000] loss: 2.299\n",
      "[8,10000] loss: 2.299\n",
      "[8,12000] loss: 2.299\n",
      "[9, 2000] loss: 2.299\n",
      "[9, 4000] loss: 2.299\n",
      "[9, 6000] loss: 2.298\n",
      "[9, 8000] loss: 2.298\n",
      "[9,10000] loss: 2.298\n",
      "[9,12000] loss: 2.298\n",
      "[10, 2000] loss: 2.298\n",
      "[10, 4000] loss: 2.298\n",
      "[10, 6000] loss: 2.297\n",
      "[10, 8000] loss: 2.298\n",
      "[10,10000] loss: 2.297\n",
      "[10,12000] loss: 2.298\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 10 %\n",
      "Accuracy of plane:  2 %\n",
      "Accuracy of   car:  0 %\n",
      "Accuracy of  bird:  0 %\n",
      "Accuracy of   cat:  0 %\n",
      "Accuracy of  deer:  0 %\n",
      "Accuracy of   dog:  8 %\n",
      "Accuracy of  frog:  0 %\n",
      "Accuracy of horse:  0 %\n",
      "Accuracy of  ship:  0 %\n",
      "Accuracy of truck: 99 %\n"
     ]
    }
   ],
   "source": [
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.000001, momentum=0.9) \n",
    " \n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "#各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习率较小（比如1e-6）时，参数更新的步幅很小，模型收敛速度较慢导致训练时间过长，甚至陷入局部最优解中无法跳出。但是，当学习率过大（比如1e-1）时，参数更新的步幅较大，模型可能会在训练过程中发生震荡或无法收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据对于⽹络的训练⾄关重要，⽽cifar10却⼜不是⼀个⾜够⼤的数据集，请对已有数据进⾏⼀\n",
    "些简单操作如翻转、平移、添加噪声等操作进⾏数据增⼴，并研究各种增强⽅法和增强数据占\n",
    "总数据的⽐例对于结果的影响，并探寻是否真的有必要进⾏数据增强操作？为什么会出现这种\n",
    "现象？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[1, 2000] loss: 2.156\n",
      "[1, 4000] loss: 1.705\n",
      "[1, 6000] loss: 1.515\n",
      "[1, 8000] loss: 1.423\n",
      "[1,10000] loss: 1.336\n",
      "[1,12000] loss: 1.287\n",
      "[2, 2000] loss: 1.199\n",
      "[2, 4000] loss: 1.142\n",
      "[2, 6000] loss: 1.145\n",
      "[2, 8000] loss: 1.091\n",
      "[2,10000] loss: 1.071\n",
      "[2,12000] loss: 1.041\n",
      "[3, 2000] loss: 0.983\n",
      "[3, 4000] loss: 0.965\n",
      "[3, 6000] loss: 0.979\n",
      "[3, 8000] loss: 0.956\n",
      "[3,10000] loss: 0.933\n",
      "[3,12000] loss: 0.926\n",
      "[4, 2000] loss: 0.862\n",
      "[4, 4000] loss: 0.865\n",
      "[4, 6000] loss: 0.850\n",
      "[4, 8000] loss: 0.862\n",
      "[4,10000] loss: 0.867\n",
      "[4,12000] loss: 0.849\n",
      "[5, 2000] loss: 0.770\n",
      "[5, 4000] loss: 0.775\n",
      "[5, 6000] loss: 0.789\n",
      "[5, 8000] loss: 0.790\n",
      "[5,10000] loss: 0.793\n",
      "[5,12000] loss: 0.801\n",
      "[6, 2000] loss: 0.724\n",
      "[6, 4000] loss: 0.706\n",
      "[6, 6000] loss: 0.743\n",
      "[6, 8000] loss: 0.760\n",
      "[6,10000] loss: 0.736\n",
      "[6,12000] loss: 0.742\n",
      "[7, 2000] loss: 0.684\n",
      "[7, 4000] loss: 0.662\n",
      "[7, 6000] loss: 0.707\n",
      "[7, 8000] loss: 0.677\n",
      "[7,10000] loss: 0.714\n",
      "[7,12000] loss: 0.699\n",
      "[8, 2000] loss: 0.636\n",
      "[8, 4000] loss: 0.641\n",
      "[8, 6000] loss: 0.666\n",
      "[8, 8000] loss: 0.654\n",
      "[8,10000] loss: 0.652\n",
      "[8,12000] loss: 0.660\n",
      "[9, 2000] loss: 0.580\n",
      "[9, 4000] loss: 0.588\n",
      "[9, 6000] loss: 0.597\n",
      "[9, 8000] loss: 0.642\n",
      "[9,10000] loss: 0.626\n",
      "[9,12000] loss: 0.619\n",
      "[10, 2000] loss: 0.557\n",
      "[10, 4000] loss: 0.572\n",
      "[10, 6000] loss: 0.596\n",
      "[10, 8000] loss: 0.596\n",
      "[10,10000] loss: 0.590\n",
      "[10,12000] loss: 0.613\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 72 %\n",
      "Accuracy of plane: 76 %\n",
      "Accuracy of   car: 79 %\n",
      "Accuracy of  bird: 62 %\n",
      "Accuracy of   cat: 51 %\n",
      "Accuracy of  deer: 69 %\n",
      "Accuracy of   dog: 63 %\n",
      "Accuracy of  frog: 79 %\n",
      "Accuracy of horse: 78 %\n",
      "Accuracy of  ship: 82 %\n",
      "Accuracy of truck: 81 %\n"
     ]
    }
   ],
   "source": [
    "#day5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "# 数据下载和标准化\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ColorJitter(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "transform_1 = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform_1)\n",
    "testloader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=0)\n",
    " \n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    " \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "class CNNNet_1(nn.Module):\n",
    "    \"\"\"\n",
    "    构建卷积神经网络\n",
    "    搭建 两个conv1 conv2 层 两个pool 层 两个全连接层\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNNet_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=36, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1296, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 36 * 6 * 6)\n",
    "        x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x\n",
    " \n",
    "class CNNNet_2(nn.Module):\n",
    "    #增加卷积层和池化层，加深网络结构\n",
    "    def __init__(self):\n",
    "        super(CNNNet_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNNNet_3(nn.Module):\n",
    "    #增加卷积核大小和步长，减小卷积层个数，增加全连接层个数\n",
    "    def __init__(self):\n",
    "        super(CNNNet_3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7, stride=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(2304, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 2304)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # 优化器的不同，将导致学习过拟合现象。\n",
    " \n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "# 特别看一下各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据增广是一种常见的数据预处理技术，可以有效提高模型的泛化能力和鲁棒性。对于较小的数据集，进行数据增广可以进一步扩充训练集，减少过拟合的风险。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过你前⼏天的探索，你已经知道了在不同的模型学习状态下相同学习率对于模型的影响不尽\n",
    "相同，⽽⼀个动态的学习率可以很⼤程度上改善这个问题，所以请你设计⾄少两种动态学习率\n",
    "⽅案并验证它们的有效性（附代码实现）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动更新学习率OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[1, 2000] loss: 2.099\n",
      "[1, 4000] loss: 1.840\n",
      "[1, 6000] loss: 1.771\n",
      "[1, 8000] loss: 1.732\n",
      "[1,10000] loss: 1.709\n",
      "[1,12000] loss: 1.705\n",
      "[2, 2000] loss: 1.678\n",
      "[2, 4000] loss: 1.682\n",
      "[2, 6000] loss: 1.659\n",
      "[2, 8000] loss: 1.675\n",
      "[2,10000] loss: 1.681\n",
      "[2,12000] loss: 1.689\n",
      "[3, 2000] loss: 1.640\n",
      "[3, 4000] loss: 1.616\n",
      "[3, 6000] loss: 1.613\n",
      "[3, 8000] loss: 1.636\n",
      "[3,10000] loss: 1.657\n",
      "[3,12000] loss: 1.660\n",
      "[4, 2000] loss: 1.620\n",
      "[4, 4000] loss: 1.633\n",
      "[4, 6000] loss: 1.642\n",
      "[4, 8000] loss: 1.665\n",
      "[4,10000] loss: 1.640\n",
      "[4,12000] loss: 1.664\n",
      "[5, 2000] loss: 1.580\n",
      "[5, 4000] loss: 1.660\n",
      "[5, 6000] loss: 1.616\n",
      "[5, 8000] loss: 1.665\n",
      "[5,10000] loss: 1.733\n",
      "[5,12000] loss: 1.722\n",
      "[6, 2000] loss: 1.671\n",
      "[6, 4000] loss: 1.665\n",
      "[6, 6000] loss: 1.658\n",
      "[6, 8000] loss: 1.674\n",
      "[6,10000] loss: 1.673\n",
      "[6,12000] loss: 1.695\n",
      "[7, 2000] loss: 1.630\n",
      "[7, 4000] loss: 1.681\n",
      "[7, 6000] loss: 1.694\n",
      "[7, 8000] loss: 1.674\n",
      "[7,10000] loss: 1.651\n",
      "[7,12000] loss: 1.659\n",
      "[8, 2000] loss: 1.676\n",
      "[8, 4000] loss: 1.750\n",
      "[8, 6000] loss: 1.712\n",
      "[8, 8000] loss: 1.683\n",
      "[8,10000] loss: 1.712\n",
      "[8,12000] loss: 1.736\n",
      "[9, 2000] loss: 1.670\n",
      "[9, 4000] loss: 1.698\n",
      "[9, 6000] loss: 1.720\n",
      "[9, 8000] loss: 1.801\n",
      "[9,10000] loss: 1.734\n",
      "[9,12000] loss: 1.704\n",
      "[10, 2000] loss: 1.755\n",
      "[10, 4000] loss: 1.649\n",
      "[10, 6000] loss: 1.762\n",
      "[10, 8000] loss: 1.715\n",
      "[10,10000] loss: 1.753\n",
      "[10,12000] loss: 1.751\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 38 %\n",
      "Accuracy of plane: 50 %\n",
      "Accuracy of   car: 56 %\n",
      "Accuracy of  bird: 21 %\n",
      "Accuracy of   cat: 34 %\n",
      "Accuracy of  deer: 29 %\n",
      "Accuracy of   dog: 30 %\n",
      "Accuracy of  frog: 51 %\n",
      "Accuracy of horse: 53 %\n",
      "Accuracy of  ship: 22 %\n",
      "Accuracy of truck: 39 %\n"
     ]
    }
   ],
   "source": [
    "#day5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "\n",
    "# 数据下载和标准化\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=0)\n",
    " \n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    " \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "class CNNNet_1(nn.Module):\n",
    "    \"\"\"\n",
    "    构建卷积神经网络\n",
    "    搭建 两个conv1 conv2 层 两个pool 层 两个全连接层\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNNet_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=36, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1296, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 36 * 6 * 6)\n",
    "        x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x\n",
    " \n",
    "\n",
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # 优化器的不同，将导致学习过拟合现象。\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.1, epochs=10, steps_per_epoch=len(trainloader))#这个调度器在整个训练过程中会让学习率在一个循环中先上升到一个最大值 0.1，然后再下降回初始值，\n",
    "#这个过程会持续 10 个 epoch，并且它会在每个 epoch 结束时更新学习率。其中，steps_per_epoch 表示每个 epoch 中包含的训练步数，len(trainloader) 则表示训练数据集的大小除以 batch_size 后的结果，即训练集中总共有多少个 batch。\n",
    "'''\n",
    "它分为三个阶段：warm-up 阶段、持续下降阶段和 cool-down 阶段。\n",
    "\n",
    "在 warm-up 阶段，学习率从初始值线性地增加到一个较高的最大值。这样做可以帮助模型迅速学习到全局信息，并避免陷入局部最优解。\n",
    "\n",
    "在持续下降阶段，学习率保持在最大值的水平上。这样做的目的是确保模型能够在接近最大学习率的情况下进行充分的探索和学习，以便更好地逼近最优解。\n",
    "\n",
    "最后，在 cool-down 阶段，学习率逐渐减小到一个较小的最小值，以便模型更稳定地收敛。这个阶段的目标是细化模型参数，提高模型的准确性。'''\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "# 各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习率衰减方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[1, 2000] loss: 2.070\n",
      "[1, 4000] loss: 1.663\n",
      "[1, 6000] loss: 1.510\n",
      "[1, 8000] loss: 1.398\n",
      "[1,10000] loss: 1.334\n",
      "[1,12000] loss: 1.270\n",
      "[2, 2000] loss: 1.168\n",
      "[2, 4000] loss: 1.146\n",
      "[2, 6000] loss: 1.140\n",
      "[2, 8000] loss: 1.096\n",
      "[2,10000] loss: 1.073\n",
      "[2,12000] loss: 1.038\n",
      "[3, 2000] loss: 0.955\n",
      "[3, 4000] loss: 0.934\n",
      "[3, 6000] loss: 0.932\n",
      "[3, 8000] loss: 0.927\n",
      "[3,10000] loss: 0.921\n",
      "[3,12000] loss: 0.927\n",
      "[4, 2000] loss: 0.702\n",
      "[4, 4000] loss: 0.682\n",
      "[4, 6000] loss: 0.671\n",
      "[4, 8000] loss: 0.654\n",
      "[4,10000] loss: 0.639\n",
      "[4,12000] loss: 0.636\n",
      "[5, 2000] loss: 0.586\n",
      "[5, 4000] loss: 0.615\n",
      "[5, 6000] loss: 0.617\n",
      "[5, 8000] loss: 0.611\n",
      "[5,10000] loss: 0.632\n",
      "[5,12000] loss: 0.633\n",
      "[6, 2000] loss: 0.567\n",
      "[6, 4000] loss: 0.586\n",
      "[6, 6000] loss: 0.583\n",
      "[6, 8000] loss: 0.573\n",
      "[6,10000] loss: 0.596\n",
      "[6,12000] loss: 0.581\n",
      "[7, 2000] loss: 0.540\n",
      "[7, 4000] loss: 0.539\n",
      "[7, 6000] loss: 0.530\n",
      "[7, 8000] loss: 0.517\n",
      "[7,10000] loss: 0.556\n",
      "[7,12000] loss: 0.536\n",
      "[8, 2000] loss: 0.515\n",
      "[8, 4000] loss: 0.521\n",
      "[8, 6000] loss: 0.527\n",
      "[8, 8000] loss: 0.539\n",
      "[8,10000] loss: 0.538\n",
      "[8,12000] loss: 0.550\n",
      "[9, 2000] loss: 0.530\n",
      "[9, 4000] loss: 0.515\n",
      "[9, 6000] loss: 0.526\n",
      "[9, 8000] loss: 0.527\n",
      "[9,10000] loss: 0.525\n",
      "[9,12000] loss: 0.539\n",
      "[10, 2000] loss: 0.528\n",
      "[10, 4000] loss: 0.517\n",
      "[10, 6000] loss: 0.531\n",
      "[10, 8000] loss: 0.518\n",
      "[10,10000] loss: 0.519\n",
      "[10,12000] loss: 0.512\n",
      "Finished Training\n",
      "Accuracy of the netwaork on the 10000 test images: 71 %\n",
      "Accuracy of plane: 77 %\n",
      "Accuracy of   car: 81 %\n",
      "Accuracy of  bird: 59 %\n",
      "Accuracy of   cat: 53 %\n",
      "Accuracy of  deer: 65 %\n",
      "Accuracy of   dog: 62 %\n",
      "Accuracy of  frog: 80 %\n",
      "Accuracy of horse: 78 %\n",
      "Accuracy of  ship: 81 %\n",
      "Accuracy of truck: 80 %\n"
     ]
    }
   ],
   "source": [
    "#day5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# 数据下载和标准化\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=0)\n",
    " \n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    " \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "class CNNNet_1(nn.Module):\n",
    "    \"\"\"\n",
    "    构建卷积神经网络\n",
    "    搭建 两个conv1 conv2 层 两个pool 层 两个全连接层\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNNet_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=36, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1296, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 36 * 6 * 6)\n",
    "        x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x\n",
    " \n",
    "\n",
    "net = CNNNet_1()\n",
    "net = net.to(device)\n",
    "# print(\"net:\",net)\n",
    " \n",
    "# 训练模型\n",
    "# 选择优化器\n",
    "import torch.optim as optim\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # 优化器的不同，将导致学习过拟合现象。\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)  # 每经过3个epoch后，学习率乘以gamma\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # 正向和反向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "print(\"Finished Training\")\n",
    " \n",
    "# 预测模型\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    " \n",
    "# 各种类别的准确率\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    " \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 众所周知，卷积核是卷积层的核⼼，尝试不同卷积核⼤⼩下的实验情况，特别注意两个极限情\n",
    "况（极⼩卷积核和极⼤卷积核），理解并叙述在不同的核⼤⼩情况下等效于我们对输⼊矩阵进\n",
    "⾏了何种操作？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[1, 2000] loss: 2.134\n",
      "[1, 4000] loss: 1.742\n",
      "[1, 6000] loss: 1.562\n",
      "[1, 8000] loss: 1.472\n",
      "[1,10000] loss: 1.405\n",
      "[1,12000] loss: 1.324\n",
      "[2, 2000] loss: 1.249\n",
      "[2, 4000] loss: 1.232\n",
      "[2, 6000] loss: 1.197\n",
      "[2, 8000] loss: 1.143\n",
      "[2,10000] loss: 1.124\n",
      "[2,12000] loss: 1.098\n",
      "[3, 2000] loss: 0.978\n",
      "[3, 4000] loss: 1.004\n",
      "[3, 6000] loss: 0.983\n",
      "[3, 8000] loss: 0.957\n",
      "[3,10000] loss: 0.969\n",
      "[3,12000] loss: 0.952\n",
      "[4, 2000] loss: 0.836\n",
      "[4, 4000] loss: 0.848\n",
      "[4, 6000] loss: 0.830\n",
      "[4, 8000] loss: 0.830\n",
      "[4,10000] loss: 0.823\n",
      "[4,12000] loss: 0.833\n",
      "[5, 2000] loss: 0.694\n",
      "[5, 4000] loss: 0.699\n",
      "[5, 6000] loss: 0.741\n",
      "[5, 8000] loss: 0.727\n",
      "[5,10000] loss: 0.735\n",
      "[5,12000] loss: 0.758\n",
      "[6, 2000] loss: 0.580\n",
      "[6, 4000] loss: 0.622\n",
      "[6, 6000] loss: 0.628\n",
      "[6, 8000] loss: 0.669\n",
      "[6,10000] loss: 0.669\n",
      "[6,12000] loss: 0.638\n",
      "[7, 2000] loss: 0.491\n",
      "[7, 4000] loss: 0.516\n",
      "[7, 6000] loss: 0.546\n",
      "[7, 8000] loss: 0.550\n",
      "[7,10000] loss: 0.580\n",
      "[7,12000] loss: 0.596\n",
      "[8, 2000] loss: 0.409\n",
      "[8, 4000] loss: 0.442\n",
      "[8, 6000] loss: 0.463\n",
      "[8, 8000] loss: 0.513\n",
      "[8,10000] loss: 0.500\n",
      "[8,12000] loss: 0.544\n",
      "[9, 2000] loss: 0.330\n",
      "[9, 4000] loss: 0.392\n",
      "[9, 6000] loss: 0.417\n",
      "[9, 8000] loss: 0.424\n",
      "[9,10000] loss: 0.462\n",
      "[9,12000] loss: 0.496\n",
      "[10, 2000] loss: 0.311\n",
      "[10, 4000] loss: 0.323\n",
      "[10, 6000] loss: 0.374\n",
      "[10, 8000] loss: 0.400\n",
      "[10,10000] loss: 0.414\n",
      "[10,12000] loss: 0.411\n",
      "Accuracy of the netwaork on the 10000 test images: 66 %\n"
     ]
    }
   ],
   "source": [
    "#day5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    " \n",
    "# 数据下载和标准化\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=0)\n",
    " \n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    " \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "\n",
    "class CNNNet_1(nn.Module):\n",
    "    \"\"\"\n",
    "    构建卷积神经网络\n",
    "    搭建 三个conv1 conv2 conv3 层 和两个pool 层 两个全连接层\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNNet_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=36, kernel_size=3, stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=36, out_channels=64, kernel_size=1, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 64 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# 小卷积核实验\n",
    "net_small_kernel = CNNNet_1()\n",
    "optimizer = optim.SGD(net_small_kernel.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向和反向传播\n",
    "        outputs = net_small_kernel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 显示损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "correct = 0\n",
    "tatal = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net_small_kernel(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tatal += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the netwaork on the 10000 test images: %d %%' % (100 * correct / tatal))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大核部分，单独拿出来训练原因在小卷积核实验中，最后一个池化层的输出大小为64 * 6 * 6，用x.view(-1, 64 * 6 * 6)重塑张量形状但在大卷积核实验中，卷积层的参数设置改变了，导致最后一个池化层的输出大小不再是64 * 6 * 6，这部分代码没问题，有问题的拿出去在另一个day6(2)里了，即大核部分，不知道为啥，在这个文件里总是莫名奇妙消失掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "现在有⼀个模拟⼈⼯标注的cifar10数据集，但是因为标注⼈员的疏忽，有很⼩⽐例的验证数据被标注错位，请你使⽤你已经训练好的模型想办法找出这些错误数据，并简单提供查找的⽅法和相关信息（请不要尝试⼈⼯审阅，相信你的模型），数据链接：https://dian-new-member-1307282200.cos.ap-nanjing.myqcloud.com/test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误数据数量： 3236\n",
      "错误数据索引： [4, 6, 20, 22, 24, 25, 26, 30, 32, 35, 36, 37, 47, 52, 53, 55, 56, 57, 58, 59, 61, 62, 64, 69, 70, 71, 76, 81, 85, 87, 99, 100, 106, 108, 109, 110, 114, 118, 120, 125, 126, 127, 128, 129, 135, 139, 140, 143, 145, 147, 154, 156, 158, 162, 163, 165, 167, 169, 171, 172, 176, 183, 184, 188, 190, 192, 195, 201, 206, 210, 211, 214, 215, 216, 221, 223, 226, 227, 228, 229, 230, 233, 236, 238, 239, 245, 246, 247, 249, 253, 254, 257, 258, 264, 266, 271, 273, 275, 277, 279, 284, 287, 295, 302, 305, 306, 308, 309, 310, 312, 314, 321, 323, 324, 327, 328, 339, 340, 346, 354, 355, 356, 359, 368, 370, 376, 378, 388, 398, 399, 405, 406, 409, 416, 418, 421, 422, 426, 427, 428, 430, 432, 434, 438, 439, 441, 444, 445, 450, 455, 456, 459, 466, 474, 478, 483, 485, 494, 503, 508, 515, 518, 519, 525, 526, 531, 532, 539, 548, 549, 550, 552, 555, 556, 558, 565, 567, 569, 573, 577, 580, 591, 618, 621, 627, 628, 629, 630, 631, 632, 633, 637, 639, 642, 647, 649, 655, 658, 661, 663, 665, 668, 669, 671, 672, 674, 675, 677, 678, 679, 680, 682, 685, 688, 689, 702, 703, 706, 707, 708, 710, 711, 718, 720, 725, 730, 731, 734, 739, 740, 744, 748, 749, 751, 755, 761, 762, 766, 767, 770, 771, 773, 779, 785, 792, 793, 796, 799, 802, 805, 806, 807, 809, 810, 811, 814, 817, 819, 820, 821, 825, 826, 829, 830, 834, 835, 836, 837, 843, 846, 848, 850, 852, 853, 857, 862, 863, 877, 878, 881, 886, 888, 889, 893, 898, 923, 924, 925, 929, 933, 936, 938, 941, 943, 945, 952, 954, 957, 965, 966, 972, 977, 981, 982, 993, 994, 1008, 1032, 1034, 1035, 1036, 1039, 1040, 1047, 1049, 1051, 1054, 1056, 1057, 1058, 1064, 1065, 1072, 1086, 1088, 1090, 1094, 1095, 1097, 1100, 1105, 1112, 1118, 1120, 1121, 1124, 1126, 1128, 1129, 1131, 1132, 1133, 1137, 1147, 1148, 1149, 1150, 1151, 1155, 1156, 1158, 1163, 1167, 1172, 1174, 1178, 1180, 1184, 1186, 1192, 1194, 1196, 1199, 1207, 1208, 1219, 1223, 1225, 1226, 1227, 1230, 1236, 1239, 1240, 1247, 1248, 1250, 1251, 1260, 1261, 1263, 1265, 1267, 1268, 1269, 1272, 1276, 1277, 1279, 1280, 1283, 1291, 1292, 1293, 1296, 1299, 1300, 1303, 1304, 1306, 1308, 1315, 1319, 1321, 1322, 1323, 1325, 1328, 1330, 1333, 1334, 1336, 1339, 1346, 1350, 1355, 1356, 1368, 1372, 1373, 1379, 1380, 1382, 1383, 1389, 1391, 1394, 1395, 1399, 1400, 1405, 1408, 1411, 1420, 1422, 1424, 1425, 1430, 1440, 1444, 1445, 1450, 1456, 1469, 1470, 1474, 1479, 1480, 1484, 1495, 1499, 1501, 1506, 1507, 1513, 1514, 1523, 1524, 1525, 1526, 1527, 1529, 1530, 1533, 1536, 1537, 1538, 1543, 1545, 1547, 1552, 1554, 1558, 1559, 1561, 1567, 1569, 1570, 1572, 1573, 1574, 1576, 1577, 1579, 1580, 1581, 1583, 1584, 1587, 1590, 1592, 1594, 1595, 1605, 1607, 1609, 1610, 1615, 1618, 1620, 1624, 1626, 1628, 1632, 1633, 1636, 1637, 1640, 1642, 1645, 1649, 1656, 1658, 1659, 1660, 1670, 1673, 1674, 1681, 1684, 1685, 1686, 1688, 1689, 1690, 1693, 1696, 1698, 1704, 1713, 1715, 1718, 1721, 1723, 1724, 1727, 1728, 1730, 1731, 1733, 1734, 1736, 1737, 1739, 1741, 1746, 1747, 1755, 1756, 1763, 1765, 1766, 1768, 1769, 1772, 1786, 1787, 1788, 1793, 1795, 1803, 1804, 1806, 1807, 1811, 1812, 1813, 1816, 1820, 1821, 1822, 1823, 1828, 1829, 1830, 1836, 1837, 1838, 1840, 1842, 1845, 1850, 1858, 1863, 1867, 1868, 1871, 1882, 1884, 1885, 1886, 1888, 1890, 1898, 1902, 1905, 1906, 1908, 1911, 1913, 1916, 1919, 1921, 1924, 1926, 1929, 1932, 1933, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1945, 1950, 1954, 1955, 1957, 1963, 1967, 1969, 1972, 1983, 1986, 1989, 1990, 1993, 1994, 1996, 2000, 2002, 2005, 2010, 2013, 2015, 2017, 2018, 2023, 2026, 2029, 2030, 2032, 2033, 2034, 2036, 2037, 2038, 2039, 2044, 2046, 2051, 2054, 2058, 2059, 2060, 2061, 2065, 2066, 2068, 2069, 2078, 2080, 2081, 2083, 2096, 2098, 2101, 2106, 2108, 2110, 2111, 2120, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2134, 2136, 2141, 2145, 2154, 2159, 2161, 2172, 2175, 2176, 2178, 2181, 2185, 2186, 2191, 2193, 2195, 2199, 2200, 2205, 2209, 2210, 2213, 2215, 2216, 2226, 2227, 2231, 2232, 2233, 2242, 2246, 2250, 2251, 2253, 2255, 2259, 2262, 2267, 2280, 2283, 2284, 2285, 2286, 2288, 2292, 2293, 2294, 2299, 2300, 2305, 2307, 2310, 2313, 2316, 2320, 2321, 2325, 2327, 2331, 2342, 2348, 2350, 2351, 2352, 2358, 2362, 2363, 2367, 2376, 2379, 2384, 2386, 2387, 2390, 2391, 2392, 2395, 2397, 2403, 2404, 2405, 2409, 2413, 2414, 2416, 2417, 2423, 2425, 2426, 2427, 2434, 2435, 2440, 2442, 2444, 2449, 2453, 2455, 2458, 2460, 2464, 2468, 2486, 2489, 2490, 2494, 2495, 2497, 2498, 2500, 2504, 2506, 2509, 2511, 2514, 2516, 2519, 2521, 2523, 2524, 2525, 2526, 2529, 2532, 2533, 2535, 2538, 2543, 2549, 2551, 2553, 2555, 2557, 2558, 2563, 2565, 2567, 2568, 2570, 2571, 2573, 2577, 2582, 2585, 2586, 2590, 2592, 2593, 2596, 2597, 2598, 2606, 2608, 2609, 2611, 2612, 2619, 2624, 2629, 2630, 2633, 2634, 2635, 2642, 2643, 2650, 2651, 2653, 2657, 2660, 2661, 2662, 2668, 2671, 2672, 2673, 2675, 2676, 2690, 2695, 2700, 2701, 2703, 2704, 2705, 2708, 2718, 2719, 2721, 2722, 2729, 2731, 2733, 2736, 2737, 2738, 2742, 2747, 2753, 2754, 2755, 2756, 2757, 2758, 2767, 2768, 2769, 2770, 2771, 2774, 2779, 2781, 2785, 2786, 2788, 2795, 2797, 2804, 2806, 2808, 2810, 2814, 2821, 2822, 2823, 2829, 2831, 2832, 2835, 2836, 2843, 2844, 2848, 2854, 2858, 2859, 2862, 2865, 2868, 2871, 2873, 2878, 2884, 2886, 2888, 2889, 2891, 2895, 2899, 2900, 2905, 2906, 2910, 2912, 2930, 2931, 2940, 2941, 2948, 2949, 2955, 2957, 2958, 2959, 2961, 2966, 2969, 2972, 2974, 2975, 2976, 2977, 2978, 2981, 2985, 2986, 2987, 2989, 2995, 2996, 2997, 3003, 3005, 3006, 3011, 3012, 3014, 3023, 3025, 3026, 3029, 3031, 3032, 3035, 3042, 3043, 3047, 3051, 3052, 3053, 3054, 3056, 3059, 3061, 3063, 3066, 3068, 3069, 3072, 3075, 3076, 3083, 3084, 3092, 3094, 3097, 3105, 3107, 3108, 3110, 3113, 3114, 3115, 3119, 3127, 3131, 3139, 3146, 3149, 3150, 3160, 3168, 3171, 3174, 3178, 3186, 3188, 3190, 3192, 3194, 3195, 3196, 3198, 3201, 3205, 3209, 3211, 3216, 3218, 3219, 3220, 3222, 3226, 3227, 3230, 3237, 3240, 3246, 3247, 3250, 3256, 3258, 3264, 3267, 3274, 3276, 3283, 3284, 3287, 3296, 3297, 3299, 3303, 3306, 3307, 3312, 3318, 3320, 3324, 3325, 3327, 3332, 3335, 3339, 3343, 3346, 3349, 3354, 3355, 3356, 3357, 3363, 3364, 3376, 3378, 3379, 3382, 3387, 3390, 3392, 3400, 3401, 3402, 3408, 3411, 3412, 3415, 3416, 3417, 3420, 3421, 3422, 3436, 3439, 3440, 3442, 3443, 3446, 3449, 3450, 3457, 3458, 3461, 3464, 3467, 3479, 3485, 3488, 3494, 3495, 3496, 3498, 3501, 3502, 3503, 3505, 3506, 3513, 3517, 3518, 3519, 3523, 3524, 3525, 3531, 3532, 3550, 3551, 3553, 3554, 3557, 3560, 3561, 3573, 3574, 3578, 3581, 3587, 3589, 3594, 3595, 3596, 3600, 3602, 3605, 3607, 3610, 3614, 3615, 3616, 3618, 3620, 3622, 3624, 3627, 3632, 3634, 3637, 3645, 3646, 3653, 3654, 3658, 3662, 3668, 3673, 3676, 3681, 3682, 3683, 3688, 3693, 3696, 3697, 3698, 3702, 3704, 3711, 3712, 3714, 3715, 3716, 3721, 3726, 3728, 3731, 3733, 3734, 3735, 3746, 3749, 3752, 3753, 3755, 3757, 3758, 3771, 3772, 3773, 3774, 3776, 3778, 3779, 3781, 3782, 3785, 3787, 3789, 3792, 3796, 3799, 3806, 3809, 3810, 3815, 3816, 3819, 3821, 3827, 3828, 3831, 3835, 3840, 3849, 3853, 3859, 3862, 3864, 3867, 3868, 3873, 3875, 3884, 3887, 3891, 3892, 3895, 3896, 3897, 3899, 3900, 3901, 3903, 3905, 3907, 3909, 3913, 3917, 3920, 3922, 3924, 3925, 3928, 3933, 3935, 3947, 3948, 3949, 3953, 3956, 3957, 3963, 3966, 3969, 3973, 3977, 3978, 3980, 3981, 3986, 3995, 3996, 3999, 4000, 4002, 4012, 4013, 4016, 4019, 4023, 4029, 4031, 4032, 4035, 4036, 4038, 4043, 4051, 4054, 4058, 4066, 4068, 4075, 4076, 4077, 4081, 4085, 4089, 4090, 4094, 4096, 4097, 4098, 4099, 4101, 4106, 4107, 4112, 4114, 4119, 4124, 4125, 4127, 4135, 4137, 4139, 4146, 4147, 4152, 4155, 4158, 4163, 4166, 4167, 4170, 4189, 4190, 4197, 4198, 4204, 4205, 4209, 4210, 4211, 4215, 4219, 4220, 4223, 4228, 4230, 4241, 4242, 4243, 4244, 4247, 4250, 4255, 4261, 4264, 4266, 4270, 4271, 4273, 4280, 4281, 4283, 4286, 4287, 4289, 4291, 4294, 4296, 4299, 4300, 4301, 4302, 4304, 4307, 4309, 4315, 4319, 4320, 4326, 4329, 4331, 4334, 4342, 4344, 4354, 4355, 4357, 4364, 4375, 4383, 4387, 4391, 4393, 4398, 4403, 4404, 4408, 4410, 4411, 4416, 4420, 4421, 4422, 4423, 4432, 4435, 4436, 4438, 4440, 4441, 4447, 4448, 4449, 4450, 4461, 4462, 4463, 4468, 4470, 4471, 4472, 4476, 4477, 4481, 4483, 4485, 4486, 4491, 4494, 4495, 4499, 4503, 4504, 4506, 4507, 4508, 4512, 4513, 4516, 4520, 4526, 4528, 4529, 4537, 4545, 4546, 4547, 4548, 4550, 4551, 4552, 4554, 4555, 4556, 4562, 4565, 4570, 4571, 4572, 4573, 4577, 4578, 4579, 4581, 4588, 4590, 4596, 4599, 4601, 4605, 4606, 4607, 4608, 4609, 4610, 4614, 4615, 4617, 4620, 4624, 4625, 4630, 4632, 4634, 4643, 4644, 4645, 4646, 4655, 4661, 4665, 4675, 4676, 4677, 4679, 4681, 4685, 4686, 4687, 4693, 4696, 4699, 4700, 4705, 4707, 4708, 4709, 4720, 4722, 4724, 4730, 4732, 4734, 4738, 4745, 4748, 4749, 4750, 4754, 4758, 4760, 4765, 4775, 4776, 4779, 4780, 4783, 4786, 4788, 4790, 4794, 4795, 4801, 4804, 4805, 4808, 4811, 4814, 4821, 4823, 4826, 4829, 4832, 4833, 4834, 4844, 4845, 4846, 4847, 4849, 4850, 4852, 4858, 4861, 4865, 4867, 4868, 4870, 4873, 4880, 4887, 4889, 4892, 4899, 4902, 4906, 4907, 4913, 4916, 4917, 4925, 4931, 4938, 4941, 4942, 4943, 4946, 4954, 4955, 4957, 4958, 4959, 4960, 4962, 4964, 4965, 4967, 4970, 4972, 4973, 4974, 4981, 4982, 4983, 4984, 4985, 4986, 4988, 4990, 4993, 4995, 4996, 4997, 5002, 5006, 5008, 5009, 5011, 5029, 5031, 5033, 5040, 5041, 5043, 5044, 5046, 5050, 5053, 5056, 5061, 5062, 5067, 5068, 5070, 5071, 5074, 5075, 5084, 5086, 5088, 5090, 5097, 5098, 5099, 5100, 5102, 5103, 5106, 5110, 5111, 5112, 5113, 5122, 5128, 5129, 5130, 5134, 5141, 5144, 5147, 5151, 5154, 5155, 5156, 5158, 5161, 5162, 5163, 5165, 5172, 5177, 5178, 5180, 5182, 5183, 5184, 5192, 5193, 5195, 5197, 5198, 5202, 5203, 5206, 5207, 5208, 5211, 5213, 5214, 5215, 5218, 5219, 5227, 5230, 5233, 5235, 5236, 5238, 5240, 5241, 5246, 5261, 5271, 5273, 5280, 5281, 5283, 5287, 5289, 5290, 5297, 5298, 5301, 5304, 5305, 5309, 5311, 5313, 5314, 5318, 5322, 5324, 5326, 5329, 5330, 5331, 5336, 5340, 5341, 5342, 5345, 5346, 5360, 5365, 5370, 5372, 5377, 5379, 5380, 5385, 5387, 5392, 5393, 5396, 5398, 5401, 5405, 5407, 5410, 5413, 5417, 5425, 5426, 5428, 5430, 5433, 5435, 5437, 5442, 5456, 5458, 5459, 5461, 5464, 5466, 5467, 5468, 5469, 5481, 5483, 5486, 5487, 5488, 5490, 5493, 5495, 5504, 5506, 5509, 5510, 5511, 5517, 5520, 5525, 5529, 5532, 5534, 5537, 5539, 5544, 5547, 5548, 5551, 5553, 5555, 5558, 5560, 5563, 5578, 5580, 5581, 5582, 5586, 5591, 5603, 5607, 5609, 5610, 5611, 5613, 5618, 5620, 5621, 5622, 5626, 5628, 5630, 5634, 5636, 5639, 5642, 5645, 5646, 5649, 5650, 5654, 5657, 5658, 5659, 5661, 5662, 5665, 5666, 5669, 5670, 5673, 5678, 5679, 5680, 5681, 5687, 5689, 5698, 5702, 5704, 5709, 5714, 5717, 5719, 5722, 5725, 5729, 5730, 5732, 5737, 5742, 5745, 5747, 5751, 5753, 5754, 5756, 5758, 5771, 5781, 5782, 5783, 5786, 5787, 5794, 5796, 5802, 5803, 5809, 5813, 5814, 5815, 5819, 5821, 5822, 5824, 5825, 5830, 5831, 5833, 5835, 5837, 5838, 5839, 5848, 5849, 5854, 5855, 5856, 5862, 5869, 5870, 5878, 5879, 5881, 5882, 5883, 5884, 5886, 5890, 5893, 5896, 5900, 5903, 5907, 5908, 5910, 5915, 5917, 5919, 5920, 5923, 5925, 5926, 5930, 5932, 5933, 5934, 5940, 5943, 5955, 5956, 5959, 5960, 5961, 5962, 5972, 5987, 5991, 5992, 5995, 5996, 5999, 6000, 6001, 6005, 6008, 6009, 6010, 6011, 6012, 6014, 6016, 6024, 6028, 6031, 6038, 6040, 6041, 6044, 6051, 6054, 6056, 6062, 6063, 6065, 6068, 6070, 6071, 6075, 6076, 6077, 6083, 6085, 6086, 6094, 6102, 6111, 6121, 6124, 6127, 6130, 6132, 6134, 6136, 6138, 6141, 6144, 6145, 6151, 6153, 6155, 6157, 6158, 6161, 6166, 6167, 6169, 6174, 6177, 6178, 6180, 6183, 6188, 6190, 6191, 6197, 6200, 6201, 6202, 6210, 6213, 6225, 6228, 6231, 6234, 6235, 6237, 6242, 6245, 6250, 6255, 6257, 6261, 6271, 6277, 6278, 6280, 6282, 6283, 6285, 6287, 6290, 6294, 6298, 6303, 6305, 6311, 6315, 6317, 6322, 6329, 6345, 6354, 6359, 6364, 6367, 6370, 6371, 6378, 6380, 6382, 6383, 6384, 6386, 6387, 6393, 6396, 6398, 6400, 6401, 6405, 6412, 6419, 6421, 6422, 6423, 6424, 6429, 6436, 6438, 6439, 6440, 6441, 6444, 6447, 6452, 6454, 6460, 6461, 6466, 6470, 6477, 6481, 6486, 6488, 6490, 6491, 6493, 6497, 6500, 6504, 6507, 6510, 6516, 6517, 6521, 6524, 6533, 6535, 6536, 6538, 6543, 6545, 6549, 6551, 6553, 6562, 6564, 6569, 6573, 6575, 6577, 6580, 6581, 6584, 6594, 6596, 6597, 6598, 6599, 6603, 6605, 6606, 6612, 6616, 6619, 6623, 6625, 6627, 6631, 6632, 6634, 6635, 6639, 6640, 6645, 6646, 6652, 6653, 6654, 6656, 6658, 6661, 6662, 6664, 6665, 6666, 6669, 6673, 6678, 6679, 6685, 6688, 6689, 6690, 6693, 6694, 6697, 6704, 6705, 6706, 6707, 6710, 6718, 6720, 6721, 6723, 6730, 6736, 6737, 6741, 6746, 6748, 6750, 6751, 6753, 6756, 6759, 6765, 6771, 6772, 6773, 6774, 6778, 6779, 6783, 6786, 6792, 6795, 6800, 6802, 6809, 6814, 6821, 6827, 6830, 6833, 6835, 6836, 6837, 6839, 6842, 6849, 6852, 6853, 6855, 6856, 6857, 6859, 6860, 6861, 6862, 6864, 6865, 6868, 6869, 6871, 6872, 6874, 6877, 6881, 6885, 6887, 6897, 6899, 6901, 6904, 6905, 6908, 6909, 6912, 6914, 6916, 6917, 6918, 6920, 6922, 6924, 6926, 6927, 6930, 6933, 6941, 6942, 6945, 6949, 6950, 6951, 6959, 6962, 6965, 6966, 6969, 6970, 6974, 6975, 6976, 6977, 6979, 6980, 6982, 6983, 6985, 6986, 6988, 6990, 6993, 6994, 6997, 7002, 7004, 7009, 7017, 7019, 7021, 7026, 7029, 7030, 7032, 7034, 7036, 7037, 7040, 7041, 7048, 7050, 7055, 7059, 7061, 7063, 7068, 7080, 7081, 7082, 7083, 7084, 7087, 7093, 7097, 7099, 7100, 7107, 7110, 7112, 7119, 7124, 7126, 7127, 7128, 7132, 7134, 7138, 7140, 7141, 7143, 7145, 7148, 7150, 7151, 7153, 7161, 7162, 7168, 7172, 7173, 7174, 7177, 7178, 7183, 7186, 7188, 7195, 7197, 7199, 7200, 7202, 7204, 7206, 7210, 7211, 7214, 7217, 7218, 7227, 7228, 7231, 7235, 7243, 7246, 7253, 7258, 7259, 7261, 7262, 7264, 7266, 7267, 7274, 7275, 7280, 7282, 7283, 7292, 7308, 7311, 7312, 7313, 7314, 7318, 7321, 7324, 7325, 7329, 7330, 7334, 7343, 7344, 7351, 7360, 7364, 7367, 7370, 7375, 7378, 7384, 7386, 7393, 7395, 7397, 7398, 7400, 7401, 7403, 7404, 7406, 7408, 7410, 7411, 7414, 7416, 7420, 7421, 7422, 7427, 7437, 7439, 7441, 7442, 7443, 7444, 7446, 7447, 7449, 7452, 7455, 7456, 7458, 7461, 7462, 7471, 7475, 7482, 7489, 7493, 7496, 7497, 7498, 7499, 7502, 7504, 7509, 7513, 7518, 7519, 7524, 7527, 7531, 7532, 7533, 7536, 7537, 7549, 7552, 7553, 7556, 7557, 7558, 7559, 7562, 7568, 7569, 7577, 7578, 7579, 7588, 7590, 7595, 7598, 7600, 7605, 7606, 7610, 7611, 7614, 7617, 7620, 7621, 7628, 7632, 7641, 7644, 7645, 7657, 7660, 7664, 7666, 7670, 7673, 7674, 7675, 7680, 7684, 7685, 7686, 7687, 7689, 7695, 7705, 7708, 7711, 7713, 7719, 7722, 7723, 7730, 7734, 7735, 7736, 7737, 7740, 7744, 7746, 7747, 7750, 7751, 7761, 7763, 7766, 7769, 7771, 7775, 7778, 7780, 7781, 7783, 7784, 7785, 7789, 7790, 7791, 7792, 7801, 7807, 7809, 7813, 7815, 7816, 7820, 7821, 7829, 7830, 7831, 7833, 7839, 7842, 7848, 7849, 7852, 7856, 7861, 7862, 7865, 7867, 7875, 7879, 7881, 7884, 7887, 7890, 7892, 7893, 7896, 7897, 7902, 7905, 7909, 7913, 7918, 7921, 7931, 7933, 7940, 7942, 7943, 7947, 7952, 7954, 7956, 7958, 7959, 7961, 7962, 7967, 7970, 7972, 7976, 7978, 7983, 7986, 7989, 8003, 8006, 8007, 8009, 8015, 8016, 8020, 8022, 8027, 8029, 8031, 8033, 8041, 8046, 8047, 8048, 8057, 8058, 8069, 8072, 8077, 8078, 8080, 8082, 8086, 8087, 8093, 8095, 8098, 8100, 8102, 8109, 8110, 8112, 8115, 8118, 8119, 8120, 8122, 8123, 8126, 8128, 8129, 8135, 8136, 8137, 8139, 8145, 8146, 8148, 8153, 8154, 8161, 8166, 8169, 8174, 8181, 8182, 8183, 8189, 8190, 8196, 8200, 8202, 8204, 8208, 8209, 8212, 8216, 8219, 8220, 8222, 8224, 8225, 8227, 8229, 8232, 8236, 8237, 8241, 8242, 8245, 8249, 8250, 8257, 8258, 8261, 8262, 8266, 8267, 8268, 8272, 8275, 8276, 8278, 8279, 8281, 8283, 8286, 8291, 8292, 8296, 8298, 8300, 8302, 8303, 8304, 8305, 8306, 8308, 8309, 8313, 8314, 8315, 8316, 8317, 8322, 8324, 8326, 8331, 8333, 8335, 8336, 8337, 8338, 8341, 8346, 8349, 8351, 8352, 8354, 8357, 8360, 8361, 8362, 8364, 8370, 8372, 8378, 8381, 8386, 8395, 8396, 8398, 8400, 8401, 8412, 8416, 8417, 8420, 8422, 8435, 8438, 8440, 8443, 8447, 8448, 8450, 8451, 8452, 8456, 8457, 8463, 8465, 8467, 8471, 8473, 8476, 8478, 8479, 8480, 8484, 8486, 8487, 8489, 8490, 8491, 8492, 8494, 8496, 8500, 8508, 8525, 8529, 8530, 8536, 8541, 8542, 8545, 8546, 8547, 8548, 8549, 8551, 8558, 8562, 8563, 8566, 8569, 8573, 8574, 8576, 8578, 8586, 8589, 8594, 8595, 8597, 8601, 8606, 8607, 8610, 8613, 8617, 8618, 8623, 8626, 8628, 8629, 8631, 8633, 8634, 8636, 8637, 8642, 8643, 8644, 8645, 8646, 8650, 8653, 8659, 8660, 8662, 8666, 8668, 8671, 8676, 8677, 8678, 8679, 8681, 8688, 8694, 8696, 8698, 8699, 8700, 8703, 8706, 8708, 8716, 8719, 8720, 8722, 8723, 8724, 8726, 8727, 8728, 8731, 8732, 8733, 8735, 8737, 8738, 8739, 8741, 8742, 8743, 8749, 8753, 8756, 8757, 8767, 8768, 8770, 8773, 8775, 8778, 8780, 8781, 8783, 8803, 8804, 8809, 8810, 8815, 8817, 8820, 8822, 8823, 8825, 8827, 8828, 8833, 8835, 8837, 8839, 8840, 8841, 8842, 8844, 8847, 8848, 8850, 8854, 8855, 8858, 8859, 8866, 8868, 8869, 8870, 8871, 8872, 8874, 8876, 8883, 8884, 8886, 8893, 8896, 8898, 8901, 8905, 8906, 8911, 8912, 8914, 8918, 8919, 8921, 8930, 8932, 8933, 8936, 8938, 8939, 8940, 8943, 8944, 8954, 8955, 8956, 8962, 8966, 8967, 8968, 8972, 8977, 8981, 8983, 8985, 8987, 8993, 8996, 8997, 8999, 9003, 9007, 9009, 9010, 9011, 9018, 9022, 9024, 9029, 9031, 9033, 9036, 9039, 9040, 9041, 9047, 9048, 9050, 9056, 9059, 9066, 9068, 9069, 9071, 9073, 9077, 9078, 9079, 9080, 9081, 9082, 9087, 9088, 9090, 9092, 9103, 9107, 9114, 9120, 9126, 9128, 9129, 9132, 9133, 9137, 9143, 9144, 9145, 9147, 9149, 9160, 9164, 9169, 9170, 9176, 9187, 9188, 9193, 9204, 9205, 9207, 9213, 9216, 9217, 9218, 9223, 9225, 9227, 9230, 9231, 9237, 9246, 9248, 9250, 9252, 9253, 9255, 9262, 9266, 9269, 9274, 9276, 9277, 9281, 9288, 9291, 9295, 9296, 9300, 9301, 9302, 9303, 9305, 9306, 9310, 9315, 9317, 9319, 9327, 9330, 9336, 9338, 9341, 9346, 9348, 9349, 9352, 9360, 9361, 9363, 9369, 9371, 9375, 9376, 9380, 9381, 9383, 9385, 9386, 9393, 9394, 9402, 9406, 9415, 9420, 9422, 9423, 9426, 9429, 9431, 9434, 9435, 9436, 9437, 9439, 9445, 9450, 9452, 9461, 9462, 9463, 9464, 9465, 9466, 9467, 9468, 9471, 9483, 9484, 9486, 9488, 9497, 9498, 9501, 9503, 9506, 9509, 9513, 9514, 9515, 9518, 9520, 9522, 9523, 9527, 9542, 9548, 9549, 9555, 9557, 9562, 9563, 9571, 9573, 9587, 9590, 9593, 9595, 9597, 9601, 9604, 9606, 9607, 9609, 9612, 9616, 9617, 9620, 9624, 9625, 9641, 9644, 9647, 9652, 9656, 9657, 9659, 9665, 9670, 9675, 9676, 9679, 9683, 9690, 9691, 9693, 9694, 9699, 9704, 9705, 9706, 9727, 9729, 9733, 9734, 9735, 9740, 9742, 9743, 9744, 9746, 9749, 9751, 9752, 9753, 9755, 9756, 9758, 9760, 9765, 9767, 9769, 9770, 9772, 9774, 9777, 9779, 9782, 9785, 9786, 9789, 9791, 9792, 9795, 9801, 9805, 9808, 9809, 9810, 9812, 9815, 9817, 9819, 9822, 9824, 9825, 9832, 9836, 9840, 9844, 9849, 9850, 9853, 9857, 9859, 9862, 9864, 9867, 9874, 9877, 9878, 9879, 9880, 9882, 9883, 9884, 9891, 9896, 9898, 9901, 9902, 9910, 9911, 9918, 9919, 9921, 9923, 9924, 9926, 9930, 9933, 9940, 9943, 9950, 9957, 9960, 9961, 9963, 9964, 9965, 9967, 9968, 9972, 9978, 9979, 9982, 9983, 9986, 9989, 9991, 9992, 9993, 9994, 9995, 9998]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# # 下载数据集\n",
    "# url = \"https://dian-new-member-1307282200.cos.ap-nanjing.myqcloud.com/test_batch\"\n",
    "# response = requests.get(url, stream=True)\n",
    "# response.raise_for_status()\n",
    "\n",
    "# # 保存数据集到本地\n",
    "# with open(\"test_batch\", \"wb\") as file:\n",
    "#     file.write(response.content)\n",
    "\n",
    "\n",
    "# 使用pickle从二进制文件中读取数据\n",
    "with open('./data/cifar-10-batches-py/test_batch', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# 将数据集转化为CIFAR-10格式，并将其替换test_batch\n",
    "test_batch = {'data': data, 'labels': np.zeros((10000,), dtype=np.uint8)}\n",
    "\n",
    "# 保存结果为二进制文件\n",
    "with open('test_batch', 'wb') as f:\n",
    "    pickle.dump(test_batch, f)\n",
    "\n",
    "\n",
    "\n",
    "class CNNNet_1(nn.Module):\n",
    "    \"\"\"\n",
    "    构建卷积神经网络\n",
    "    搭建 两个conv1 conv2 层 两个pool 层 两个全连接层\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNNet_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=36, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1296, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 36 * 6 * 6)\n",
    "        x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x\n",
    " \n",
    "\n",
    "# 加载模型\n",
    "net = CNNNet_1()\n",
    "net.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "# 错误数据的索引列表\n",
    "misclassified_indices = []\n",
    "\n",
    "# 对验证数据集进行推断并查找错误数据\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        if predicted != labels:\n",
    "            misclassified_indices.append(i)\n",
    "\n",
    "# 输出错误数据的数量与索引\n",
    "print(\"错误数据数量：\", len(misclassified_indices))\n",
    "print(\"错误数据索引：\", misclassified_indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
